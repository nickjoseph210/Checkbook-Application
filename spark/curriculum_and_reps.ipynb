{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum and Reps\n",
    "\n",
    "- First line is curriculum code with notes.  \n",
    "\n",
    "- Second line is my fingers actually typing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "# 'SparkSession' is lets you work with dataframes and tables using SQL-like queries\n",
    "\n",
    "# 'builder' creates the Sparksession\n",
    "\n",
    "# 'getOrCreate()' gets an existing SparkSession if there is one.  If there's NOT one, \n",
    "# 'getOrCreate()' makes one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n group\n",
       "0  0     b\n",
       "1  1     b\n",
       "2  2     c\n",
       "3  3     a\n",
       "4  4     c"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(456)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(\n",
    "    dict(n=np.arange(20), group=np.random.choice(list(\"abc\"), 20))\n",
    ")\n",
    "\n",
    "# \"Create a pandas DataFrame with 20 rows numbered 0-19.  \n",
    "# \"First column is 'n,' second column is 'group.'  in 'group' column, give me \n",
    "# \"20 random letters either 'a, b, or c.'\"\n",
    "\n",
    "pandas_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n group\n",
       "0  0     c\n",
       "1  1     b\n",
       "2  2     c\n",
       "3  3     a\n",
       "4  4     b"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = (456)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(\n",
    "    dict(n=np.arange(20), group=np.random.choice(list(\"abc\"), 20))\n",
    ")\n",
    "\n",
    "pandas_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: bigint, group: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = spark.createDataFrame(pandas_dataframe)\n",
    "# df\n",
    "\n",
    "# converts this pandas df to a spark df w/ 'createDataFrame(what you want to turn into \n",
    "# spark dataframe)'\n",
    "\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**^^ 'bigint' is a Java integer in the pentillions, so just think of it as an integer**\n",
    "\n",
    "- also look how it SAYS it's a DataFrame, but it doesn't SHOW us a datframe, like Pandas does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  n|group|\n",
      "+---+-----+\n",
      "|  0|    c|\n",
      "|  1|    b|\n",
      "|  2|    c|\n",
      "|  3|    a|\n",
      "|  4|    b|\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**^^ '.show( )' makes spark get off its ass and get to work** \n",
    "\n",
    "- Next two lines are another example of what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, n: string, group: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # describes it's a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----+\n",
      "|summary|                n|group|\n",
      "+-------+-----------------+-----+\n",
      "|  count|               20|   20|\n",
      "|   mean|              9.5| null|\n",
      "| stddev|5.916079783099616| null|\n",
      "|    min|                0|    a|\n",
      "|    max|               19|    c|\n",
      "+-------+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show() # SHOWS us a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data # our data library from intro to pandas days\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)\n",
    "\n",
    "# note: if pandas df, it'd just be 'mpg,' but with spark it's 'mpg.show()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'hwy'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.hwy # shows us that 'hwy' is a column object.  It's just a vertical table slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hwy: bigint, cty: bigint, model: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use '.select()' to get Spark to show the datatypes in the columns\n",
    "\n",
    "mpg.select(mpg.hwy, mpg.cty, mpg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types are great, but we need to see details, \n",
    "# So we need to ask Spark to \"Show\" them to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------------+\n",
      "|hwy|cty|             model|\n",
      "+---+---+------------------+\n",
      "| 29| 18|                a4|\n",
      "| 29| 21|                a4|\n",
      "| 31| 20|                a4|\n",
      "| 30| 21|                a4|\n",
      "| 26| 16|                a4|\n",
      "| 26| 18|                a4|\n",
      "| 27| 18|                a4|\n",
      "| 26| 18|        a4 quattro|\n",
      "| 25| 16|        a4 quattro|\n",
      "| 28| 20|        a4 quattro|\n",
      "| 27| 19|        a4 quattro|\n",
      "| 25| 15|        a4 quattro|\n",
      "| 25| 17|        a4 quattro|\n",
      "| 25| 17|        a4 quattro|\n",
      "| 25| 15|        a4 quattro|\n",
      "| 24| 15|        a6 quattro|\n",
      "| 25| 17|        a6 quattro|\n",
      "| 23| 16|        a6 quattro|\n",
      "| 20| 14|c1500 suburban 2wd|\n",
      "| 15| 11|c1500 suburban 2wd|\n",
      "+---+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.hwy, mpg.cty, mpg.model).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'(hwy + 1)'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark lets you do vector math up and down a single column\n",
    "\n",
    "mpg.hwy + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|hwy|(hwy + 1)|\n",
      "+---+---------+\n",
      "| 29|       30|\n",
      "| 29|       30|\n",
      "| 31|       32|\n",
      "| 30|       31|\n",
      "| 26|       27|\n",
      "+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the column with the 1 added to the numbers, select then show:\n",
    "\n",
    "mpg.select(mpg.hwy, mpg.hwy + 1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**^^ You can see that the math was applied by showing 'mpg.hwy' next to 'mpg.hwy+1**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|highway_miles|\n",
      "+-------------+\n",
      "|           29|\n",
      "|           29|\n",
      "|           31|\n",
      "|           30|\n",
      "|           26|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Format for renaming a column:\n",
    "\n",
    "# df_name.select(df.column.alias(\"new_name\")).show()\n",
    "\n",
    "mpg.select(mpg.hwy.alias(\"highway_miles\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------+\n",
      "|highway_mileage|highway_mileage_halved|\n",
      "+---------------+----------------------+\n",
      "|             29|                  14.5|\n",
      "|             29|                  14.5|\n",
      "|             31|                  15.5|\n",
      "|             30|                  15.0|\n",
      "|             26|                  13.0|\n",
      "+---------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To store column objects as variables and reference them:\n",
    "\n",
    "col1 = mpg.hwy.alias(\"highway_mileage\")\n",
    "col2 = (mpg.hwy / 2).alias(\"highway_mileage_halved\")\n",
    "mpg.select(col1, col2).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Spark, the 'col' and 'expr' create columns.  \n",
    "\n",
    "- they need to be imported from the 'pyspark.sql.functions' library\n",
    "\n",
    "- 'col' lets you create a column and use it just like you would in the df Pandas work\n",
    "\n",
    "- 'expr' does everything 'col' does, but is more powerful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'hwy'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col(\"hwy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that you've created a 'hwy' column, you can do math with it, rename it, etc.  IE as soon as you col(\"something\") you can do all the manipulations to it you want, just like in the code above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+---------------+\n",
      "|highway_mileage|city_mileage|average_mileage|\n",
      "+---------------+------------+---------------+\n",
      "|             29|          18|           23.5|\n",
      "|             29|          21|           25.0|\n",
      "|             31|          20|           25.5|\n",
      "|             30|          21|           25.5|\n",
      "|             26|          16|           21.0|\n",
      "|             26|          18|           22.0|\n",
      "|             27|          18|           22.5|\n",
      "|             26|          18|           22.0|\n",
      "|             25|          16|           20.5|\n",
      "|             28|          20|           24.0|\n",
      "+---------------+------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNote the format:\\n\\ndf.select(col(\"col_name\").alias(\"new_col_name\"),\\n        df.df_col_name.alias(\"new_df_col_name\"),\\n        variable_name.alias(\"new_variable_name\"), .show(10)\\n        \\nWithin the code, I use the column I created using \\'col\\', the column name from the\\nexisting dataframe, and my variable name.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_column = (col(\"hwy\") + col(\"cty\")) / 2\n",
    "\n",
    "mpg.select(col(\"hwy\").alias(\"highway_mileage\"), # change from 'col' to 'higheway_mileage'\n",
    "          mpg.cty.alias(\"city_mileage\"), # change from 'cty' to 'city_mileage'\n",
    "          avg_column.alias(\"average_mileage\"),).show(10) # change 'avg_column' to 'average_mileage'\n",
    "\n",
    "\"\"\"\n",
    "Note the format:\n",
    "\n",
    "df.select(col(\"col_name\").alias(\"new_col_name\"),\n",
    "        df.df_col_name.alias(\"new_df_col_name\"),\n",
    "        variable_name.alias(\"new_variable_name\"), .show(10)\n",
    "        \n",
    "Within the code, I use the column I created using 'col', the column name from the\n",
    "existing dataframe, and my variable name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now for 'expr':**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------------+-------------------+\n",
      "|hwy|(hwy + 1)|highway_mileage|highway_incremented|\n",
      "+---+---------+---------------+-------------------+\n",
      "| 29|       30|             29|                 30|\n",
      "| 29|       30|             29|                 30|\n",
      "| 31|       32|             31|                 32|\n",
      "| 30|       31|             30|                 31|\n",
      "| 26|       27|             26|                 27|\n",
      "| 26|       27|             26|                 27|\n",
      "| 27|       28|             27|                 28|\n",
      "| 26|       27|             26|                 27|\n",
      "| 25|       26|             25|                 26|\n",
      "| 28|       29|             28|                 29|\n",
      "+---+---------+---------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    expr(\"hwy\"), # just like I'd do 'col'\n",
    "    expr(\"hwy + 1\"), # adding one down the entire column = vector math\n",
    "    expr(\"hwy AS highway_mileage\"), # creates alias like I would in an MySQL query\n",
    "    expr(\"hwy + 1 AS highway_incremented\"), # renames the column I'm adding 1 to\n",
    "    ).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+\n",
      "|highway|highway|highway|highway|\n",
      "+-------+-------+-------+-------+\n",
      "|     29|     29|     29|     29|\n",
      "|     29|     29|     29|     29|\n",
      "|     31|     31|     31|     31|\n",
      "|     30|     30|     30|     30|\n",
      "|     26|     26|     26|     26|\n",
      "+-------+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# These are 4 ways to express the same thing:\n",
    "\n",
    "mpg.select(\n",
    "    mpg.hwy.alias(\"highway\"),\n",
    "    col(\"hwy\").alias(\"highway\"),\n",
    "    expr(\"hwy\").alias(\"highway\"),\n",
    "    expr(\"hwy AS highway\"),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark SQL\n",
    "\n",
    "- lets us write against our spark df's using SQL quries (kind of like what we did when we gave aliases using 'expr' above)\n",
    "\n",
    "Couple of things you have to do before using Spark SQL:\n",
    "\n",
    "1.) You gotta register your table with Spark\n",
    "\n",
    "2.) Now that it's registered, we can begin sending SQL queries to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register\n",
    "\n",
    "mpg.createOrReplaceTempView(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hwy: bigint, cty: bigint, avg: double]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can start sending queries\n",
    "\n",
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT hwy, cty, (hwy + cty) / 2 AS avg\n",
    "FROM mpg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ Okay, so this shows us the dtype of the columns, but doesn't show us anything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|hwy|cty| avg|\n",
      "+---+---+----+\n",
      "| 29| 18|23.5|\n",
      "| 29| 21|25.0|\n",
      "| 31| 20|25.5|\n",
      "| 30| 21|25.5|\n",
      "| 26| 16|21.0|\n",
      "| 26| 18|22.0|\n",
      "| 27| 18|22.5|\n",
      "| 26| 18|22.0|\n",
      "| 25| 16|20.5|\n",
      "| 28| 20|24.0|\n",
      "+---+---+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT hwy, cty, (hwy + cty)/ 2 AS avg\n",
    "FROM mpg\n",
    "\"\"\").show(10)\n",
    "\n",
    "# Note format:\n",
    "#     (\n",
    "#     triple quotes\n",
    "#     SELECT columns_you, want_to, see\n",
    "#     FROM df_you're_looking_at\n",
    "#     triple quotes\n",
    "#     ).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typecasting\n",
    "\n",
    "**Because machine learning models only accept integer datatypes, we'll need to change datatypes as we go along in order for the models to read them.  'TYPECASTING' lets us us this, similar to '.astype( )' in Pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manufacturer', 'string'),\n",
       " ('model', 'string'),\n",
       " ('displ', 'double'),\n",
       " ('year', 'bigint'),\n",
       " ('cyl', 'bigint'),\n",
       " ('trans', 'string'),\n",
       " ('drv', 'string'),\n",
       " ('cty', 'bigint'),\n",
       " ('hwy', 'bigint'),\n",
       " ('fl', 'string'),\n",
       " ('class', 'string')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the datatypes in mpg\n",
    "\n",
    "mpg.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ We see 3 different datatypes: 'string,' 'double,' and 'bigint.'  You can also do this by using 'mpg.printSchema()' - 'schema' = the structure of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- displ: double (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- cyl: long (nullable = true)\n",
      " |-- trans: string (nullable = true)\n",
      " |-- drv: string (nullable = true)\n",
      " |-- cty: long (nullable = true)\n",
      " |-- hwy: long (nullable = true)\n",
      " |-- fl: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To convert to a different datatype, we use 'cast':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hwy: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.hwy.cast(\"string\")).printSchema()\n",
    "\n",
    "# we are selecting the 'hwy' column from the 'mpg' df\n",
    "# and changing it from a 'bigint' (or 'long') into a 'string' using 'cast'\n",
    "# the output below shows us this is what we've accomplished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If a value cannot be converted using '.cast( )', then it will be replaced with a 'null' as we can see from the following**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     model|model|\n",
      "+----------+-----+\n",
      "|        a4| null|\n",
      "|        a4| null|\n",
      "|        a4| null|\n",
      "|        a4| null|\n",
      "|        a4| null|\n",
      "|        a4| null|\n",
      "|        a4| null|\n",
      "|a4 quattro| null|\n",
      "|a4 quattro| null|\n",
      "|a4 quattro| null|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.model, mpg.model.cast(\"int\")).show(10)\n",
    "\n",
    "# \"select 'mpg.model' from 'mpg' and make cast its dtype from 'string' to 'int'\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
