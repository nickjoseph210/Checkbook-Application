{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "The name of the column should be language\n",
    "\n",
    "View the schema of the dataframe\n",
    "\n",
    "Output the shape of the dataframe\n",
    "\n",
    "Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>teachers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "      <td>2</td>\n",
       "      <td>Ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruby</td>\n",
       "      <td>1</td>\n",
       "      <td>Zach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HTML</td>\n",
       "      <td>3</td>\n",
       "      <td>Self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>0</td>\n",
       "      <td>Zach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RedLion</td>\n",
       "      <td>3</td>\n",
       "      <td>Self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeywell</td>\n",
       "      <td>3</td>\n",
       "      <td>Randy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    language  experience_level teachers\n",
       "0     Python                 2     Ryan\n",
       "1       Ruby                 1     Zach\n",
       "2       HTML                 3     Self\n",
       "3       Java                 1     Ryan\n",
       "4        C++                 0     Zach\n",
       "5    RedLion                 3     Self\n",
       "6  Honeywell                 3    Randy"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "table_data = {\"language\" : [\"Python\", \"Ruby\", \"HTML\", \"Java\", \"C++\", \"RedLion\", \"Honeywell\"],\n",
    "             \"experience_level\" : [2, 1, 3, 1, 0, 3, 3],\n",
    "             \"teachers\" : [\"Ryan\", \"Zach\", \"Self\", \"Ryan\", \"Zach\", \"Self\", \"Randy\"]}\n",
    "\n",
    "pandas_df = pd.DataFrame(table_data, columns=[\"language\", \"experience_level\", \"teachers\"])\n",
    "\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string, experience_level: bigint, teachers: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning it into a Spark dataframe:\n",
    "\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- experience_level: long (nullable = true)\n",
      " |-- teachers: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the schema (structure)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 rows 3 columns\n"
     ]
    }
   ],
   "source": [
    "# Show the shape\n",
    "\n",
    "df_shape = df.count(), len(df.columns)\n",
    "\n",
    "print(df.count(), \"rows\", len(df.columns), \"columns\")\n",
    "\n",
    "\n",
    "\n",
    "# def spark_shape(self):\n",
    "#     return (self.count(), len(self.columns))\n",
    "# pyspark.sql.dataframe.DataFrame.shape = spark_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+--------+\n",
      "|languages|experience_level|teachers|\n",
      "+---------+----------------+--------+\n",
      "|   Python|               2|    Ryan|\n",
      "|     Ruby|               1|    Zach|\n",
      "|     HTML|               3|    Self|\n",
      "|     Java|               1|    Ryan|\n",
      "|      C++|               0|    Zach|\n",
      "+---------+----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, language: string, experience_level: string, teachers: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+--------+\n",
      "|summary|language|  experience_level|teachers|\n",
      "+-------+--------+------------------+--------+\n",
      "|  count|       7|                 7|       7|\n",
      "|   mean|    null|1.8571428571428572|    null|\n",
      "| stddev|    null|1.2149857925879117|    null|\n",
      "|    min|     C++|                 0|   Randy|\n",
      "|    max|    Ruby|                 3|    Zach|\n",
      "+-------+--------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "\n",
    "The 1999 audi a4 has a 4 cylinder engine.\n",
    "For each vehicle.\n",
    "\n",
    "Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|     model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|        a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|        a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|        a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading mpg\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "\n",
    "mpg.show(10)\n",
    "# from pydataset import data\n",
    "\n",
    "# mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "# mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- displ: double (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- cyl: long (nullable = true)\n",
      " |-- trans: string (nullable = true)\n",
      " |-- drv: string (nullable = true)\n",
      " |-- cty: long (nullable = true)\n",
      " |-- hwy: long (nullable = true)\n",
      " |-- fl: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[manufacturer: string, model: string, displ: double, year: bigint, cyl: bigint, trans: string, drv: string, cty: bigint, hwy: bigint, fl: string, class: string, details: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a column of output with that reading:\n",
    "\n",
    "from pyspark.sql.functions import col, expr, lit, when\n",
    "\n",
    "\n",
    "mpg = mpg.withColumn('details', lit('these are the details'))\n",
    "\n",
    "display(mpg)\n",
    "\n",
    "# # The 1999 audi a4 has a 4 cylinder engine. For each vehicle.\n",
    "\n",
    "# from pyspark.sql.functions import col, expr, lit, when\n",
    "\n",
    "# def car_description(year, model, car):\n",
    "    \n",
    "#     date = mpg.select(mpg.year)\n",
    "#     maker = mpg.select(mpg.manufacturer)\n",
    "#     style = mpg.select(mpg.model)\n",
    "#     pistons = mpg.select(mpg.cyl)\n",
    "\n",
    "#     return f\"The {date} {maker} {style} has a {pistons} engine.\"\n",
    "\n",
    "# car_description(\"2008\", \"a4 quattro\", \"audi\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----------------+------------------+-----------------+------------------+----------+---+------------------+-----------------+----+-------+--------------------+\n",
      "|summary|manufacturer|            model|             displ|             year|               cyl|     trans|drv|               cty|              hwy|  fl|  class|             details|\n",
      "+-------+------------+-----------------+------------------+-----------------+------------------+----------+---+------------------+-----------------+----+-------+--------------------+\n",
      "|  count|         234|              234|               234|              234|               234|       234|234|               234|              234| 234|    234|                 234|\n",
      "|   mean|        null|             null| 3.471794871794873|           2003.5| 5.888888888888889|      null|4.0|16.858974358974358|23.44017094017094|null|   null|                null|\n",
      "| stddev|        null|             null|1.2919590310839348|4.509646313320409|1.6115344846842894|      null|0.0| 4.255945678889395|5.954643441166446|null|   null|                null|\n",
      "|    min|        audi|      4runner 4wd|               1.6|             1999|                 4|  auto(av)|  4|                 9|               12|   c|2seater|these are the det...|\n",
      "|    max|  volkswagen|toyota tacoma 4wd|               7.0|             2008|                 8|manual(m6)|  r|                35|               44|   r|    suv|these are the det...|\n",
      "+-------+------------+-----------------+------------------+-----------------+------------------+----------+---+------------------+-----------------+----+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**^^ Need Help with this one.  Spent WAYYYY too long on it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Scan ExistingRDD[manufacturer#409,model#410,displ#411,year#412L,cyl#413L,trans#414,drv#415,cty#416L,hwy#417L,fl#418,class#419]\n"
     ]
    }
   ],
   "source": [
    "# transform the columns\n",
    "\n",
    "mpg.explain() # '.explain()' shows us how spark is thinking about our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [trans#414]\n",
      "+- Scan ExistingRDD[manufacturer#409,model#410,displ#411,year#412L,cyl#413L,trans#414,drv#415,cty#416L,hwy#417L,fl#418,class#419]\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.trans).explain() # shows us how Spark is thinking about our 'trans' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
