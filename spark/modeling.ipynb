{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data # gets the 'tips' dataset\n",
    "import pyspark\n",
    "import pyspark.ml # the machine learning module within pyspark\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(data('tips'))\n",
    "\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(df: pyspark.sql.DataFrame):\n",
    "    return df.count(), len(df.columns) # function to define a shape function \n",
    "\n",
    "# spark doesn't have a built-in function for shape that pandas does\n",
    "# b/c spark is lazy and doesn't assemble the data in any order - it's all broken up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "- We'll first demonstrate a regression problem: predicting the tip amount.\n",
    "\n",
    "- Spark also has functions for time-series and NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     12.54| 2.5|  Male|    No|Sun|Dinner|   2|\n",
      "|     13.37| 2.0|  Male|    No|Sat|Dinner|   2|\n",
      "|     13.94|3.06|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     15.77|2.23|Female|    No|Sat|Dinner|   2|\n",
      "|     16.04|2.24|  Male|    No|Sat|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.31| 2.0|  Male|    No|Sat|Dinner|   3|\n",
      "|     16.93|3.07|Female|    No|Sat|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     17.46|2.54|  Male|    No|Sun|Dinner|   2|\n",
      "|     17.78|3.27|  Male|    No|Sat|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyspark.ml.feature.RFormula\n",
    "\n",
    "- RFormula is a ml feature in pyspark that describes how we're going to make predictions, but was written for 'R' programming language\n",
    "\n",
    "- tip ~ total_bill: predict tip based on total bill\n",
    "    \n",
    "- tip ~ total_bill + size: predict tip based on total bill and size\n",
    "    \n",
    "- tip ~ .: predict tip based on all the other features in the dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| [8.77,2.0]|  2.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|[10.27,2.0]| 1.71|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|[10.29,2.0]|  2.6|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|[10.33,3.0]| 1.67|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|[10.34,3.0]| 1.66|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nb: spark's rformula does encoding\n",
    "rf = pyspark.ml.feature.RFormula(formula=\"tip ~ total_bill + size\").fit(train)\n",
    "# read as 'the 'tip' is a function of the 'total_bill' and 'size'\n",
    "\n",
    "rf.transform(train).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'features' and 'label' columns are the shape/name required for pyspark.ml\n",
    "\n",
    "- 'features' and 'label' were columns added by the RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   features|label|\n",
      "+-----------+-----+\n",
      "| [8.77,2.0]|  2.0|\n",
      "|[10.27,2.0]| 1.71|\n",
      "|[10.29,2.0]|  2.6|\n",
      "|[10.33,3.0]| 1.67|\n",
      "|[10.34,3.0]| 1.66|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_input = rf.transform(train).select('features', 'label')\n",
    "train_input.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create, fit, and use the model**\n",
    "\n",
    "**NB:\n",
    "Unlike sklearn, each step produces a new object!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_b55671c562a0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = pyspark.ml.regression.LinearRegression() #this is where I'd set my hyperparameters\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------------------+\n",
      "|   features|label|        prediction|\n",
      "+-----------+-----+------------------+\n",
      "| [8.77,2.0]|  2.0|1.8431748565237749|\n",
      "|[10.27,2.0]| 1.71|1.9846902983830235|\n",
      "|[10.29,2.0]|  2.6|1.9865771709411468|\n",
      "|[10.33,3.0]| 1.67|2.1519321354884804|\n",
      "|[10.34,3.0]| 1.66|2.1528755717675416|\n",
      "+-----------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_fit = lr.fit(train_input)\n",
    "lr_fit.transform(train_input).show(5)\n",
    "\n",
    "# unlike in pandas, all the ols and y-hat stuff is done for us in spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x11c0595d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5083641431094578, 0.9254138907986432)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.summary.r2, lr_fit.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coefficientStandardErrors',\n",
       " 'degreesOfFreedom',\n",
       " 'devianceResiduals',\n",
       " 'explainedVariance',\n",
       " 'featuresCol',\n",
       " 'labelCol',\n",
       " 'meanAbsoluteError',\n",
       " 'meanSquaredError',\n",
       " 'numInstances',\n",
       " 'objectiveHistory',\n",
       " 'pValues',\n",
       " 'predictionCol',\n",
       " 'predictions',\n",
       " 'r2',\n",
       " 'r2adj',\n",
       " 'residuals',\n",
       " 'rootMeanSquaredError',\n",
       " 'tValues',\n",
       " 'totalIterations']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(lr_fit.summary) if not x.startswith('_')] # shows me all the stuff I can use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did we do on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "|total_bill| tip| sex|smoker|day|  time|size|   features|label|        prediction|\n",
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "|      9.55|1.45|Male|    No|Sat|Dinner|   2| [9.55,2.0]| 1.45|1.9167628862905841|\n",
      "|      9.68|1.32|Male|    No|Sun|Dinner|   2| [9.68,2.0]| 1.32|1.9290275579183855|\n",
      "|      9.94|1.56|Male|    No|Sun|Dinner|   2| [9.94,2.0]| 1.56|1.9535569011739888|\n",
      "|     11.24|1.76|Male|   Yes|Sat|Dinner|   2|[11.24,2.0]| 1.76| 2.076203617452004|\n",
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_input = rf.transform(test)\n",
    "lr_fit.transform(test_input).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.272225453071824"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.RegressionEvaluator()\n",
    "rmse = evaluator.evaluate(lr_fit.transform(test_input))\n",
    "rmse\n",
    "\n",
    "# this is the root mean square error on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "- we're trying to predict 'time'\n",
    "\n",
    "- Preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| [8.77,2.0]|  0.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|[10.27,2.0]|  0.0|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|[10.29,2.0]|  0.0|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|[10.33,3.0]|  0.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|[10.34,3.0]|  0.0|\n",
      "|     12.54| 2.5|  Male|    No|Sun|Dinner|   2|[12.54,2.0]|  0.0|\n",
      "|     13.37| 2.0|  Male|    No|Sat|Dinner|   2|[13.37,2.0]|  0.0|\n",
      "|     13.94|3.06|  Male|    No|Sun|Dinner|   2|[13.94,2.0]|  0.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|[14.78,2.0]|  0.0|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|[14.83,2.0]|  0.0|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|[15.04,2.0]|  0.0|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|[15.42,2.0]|  0.0|\n",
      "|     15.77|2.23|Female|    No|Sat|Dinner|   2|[15.77,2.0]|  0.0|\n",
      "|     16.04|2.24|  Male|    No|Sat|Dinner|   3|[16.04,3.0]|  0.0|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|[16.29,3.0]|  0.0|\n",
      "|     16.31| 2.0|  Male|    No|Sat|Dinner|   3|[16.31,3.0]|  0.0|\n",
      "|     16.93|3.07|Female|    No|Sat|Dinner|   3|[16.93,3.0]|  0.0|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|[16.97,3.0]|  0.0|\n",
      "|     17.46|2.54|  Male|    No|Sun|Dinner|   2|[17.46,2.0]|  0.0|\n",
      "|     17.78|3.27|  Male|    No|Sat|Dinner|   2|[17.78,2.0]|  0.0|\n",
      "|     17.92|4.08|  Male|    No|Sat|Dinner|   2|[17.92,2.0]|  0.0|\n",
      "|     18.29| 3.0|  Male|    No|Sun|Dinner|   2|[18.29,2.0]|  0.0|\n",
      "|     18.35| 2.5|  Male|    No|Sat|Dinner|   4|[18.35,4.0]|  0.0|\n",
      "|     18.69|2.31|  Male|    No|Sat|Dinner|   3|[18.69,3.0]|  0.0|\n",
      "|     19.49|3.51|  Male|    No|Sun|Dinner|   2|[19.49,2.0]|  0.0|\n",
      "|     19.65| 3.0|Female|    No|Sat|Dinner|   2|[19.65,2.0]|  0.0|\n",
      "|     19.82|3.18|  Male|    No|Sat|Dinner|   2|[19.82,2.0]|  0.0|\n",
      "|     20.29|2.75|Female|    No|Sat|Dinner|   2|[20.29,2.0]|  0.0|\n",
      "|     20.29|3.21|  Male|   Yes|Sat|Dinner|   2|[20.29,2.0]|  0.0|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|[20.65,3.0]|  0.0|\n",
      "|     20.69|2.45|Female|    No|Sat|Dinner|   4|[20.69,4.0]|  0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|[21.01,3.0]|  0.0|\n",
      "|      21.7| 4.3|  Male|    No|Sat|Dinner|   2| [21.7,2.0]|  0.0|\n",
      "|     22.23| 5.0|  Male|    No|Sun|Dinner|   2|[22.23,2.0]|  0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|[23.68,2.0]|  0.0|\n",
      "|     24.06| 3.6|  Male|    No|Sat|Dinner|   3|[24.06,3.0]|  0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|[24.59,4.0]|  0.0|\n",
      "|     25.56|4.34|  Male|    No|Sun|Dinner|   4|[25.56,4.0]|  0.0|\n",
      "|     26.41| 1.5|Female|    No|Sat|Dinner|   2|[26.41,2.0]|  0.0|\n",
      "|     28.55|2.05|  Male|    No|Sun|Dinner|   3|[28.55,3.0]|  0.0|\n",
      "|      30.4| 5.6|  Male|    No|Sun|Dinner|   4| [30.4,4.0]|  0.0|\n",
      "|     31.27| 5.0|  Male|    No|Sat|Dinner|   3|[31.27,3.0]|  0.0|\n",
      "|      32.4| 6.0|  Male|    No|Sun|Dinner|   4| [32.4,4.0]|  0.0|\n",
      "|     34.81| 5.2|Female|    No|Sun|Dinner|   4|[34.81,4.0]|  0.0|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|[35.26,4.0]|  0.0|\n",
      "|     39.42|7.58|  Male|    No|Sat|Dinner|   4|[39.42,4.0]|  0.0|\n",
      "|     48.27|6.73|  Male|    No|Sat|Dinner|   4|[48.27,4.0]|  0.0|\n",
      "|      3.07| 1.0|Female|   Yes|Sat|Dinner|   1| [3.07,1.0]|  0.0|\n",
      "|      5.75| 1.0|Female|   Yes|Fri|Dinner|   2| [5.75,2.0]|  0.0|\n",
      "|      7.25| 1.0|Female|    No|Sat|Dinner|   1| [7.25,1.0]|  0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = pyspark.ml.feature.RFormula(formula='time ~ total_bill + size').fit(train)\n",
    "train_input = rf.transform(train)\n",
    "train_input.show(50)\n",
    "\n",
    "# dinner's going to be 0\n",
    "# lunch is going to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pyspark.ml.classification.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fit = lr.fit(train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'areaUnderROC',\n",
       " 'fMeasureByLabel',\n",
       " 'fMeasureByThreshold',\n",
       " 'falsePositiveRateByLabel',\n",
       " 'featuresCol',\n",
       " 'labelCol',\n",
       " 'labels',\n",
       " 'objectiveHistory',\n",
       " 'pr',\n",
       " 'precisionByLabel',\n",
       " 'precisionByThreshold',\n",
       " 'predictionCol',\n",
       " 'predictions',\n",
       " 'probabilityCol',\n",
       " 'recallByLabel',\n",
       " 'recallByThreshold',\n",
       " 'roc',\n",
       " 'totalIterations',\n",
       " 'truePositiveRateByLabel',\n",
       " 'weightedFMeasure',\n",
       " 'weightedFalsePositiveRate',\n",
       " 'weightedPrecision',\n",
       " 'weightedRecall',\n",
       " 'weightedTruePositiveRate']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(lr_fit.summary) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on area under the ROC Curve:**\n",
    "    \n",
    "- produce a curve where each point on the curve is the True Positive versus the False Positive; multiple points are found by adjusting the threshold for the model\n",
    "\n",
    "- Works for classification models and other models that predict probability in addition to yes / no\n",
    "\n",
    "- Gives us a number between 0 and 1; the closer to 1, the better\n",
    "\n",
    "- When I hear 'AOC,' that's short for the 'Area Under the Curve.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6430830039525691"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# area under TPR (recall) vs FPR (FP / (FP + TN)) curve\n",
    "# https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "lr_fit.summary.areaUnderROC\n",
    "\n",
    "# how we did on the test data|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5809716599190283"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator()\n",
    "test_auc = evaluator.evaluate(lr_fit.transform(rf.transform(test)))\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|   features|label|\n",
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "|      9.55|1.45|  Male|    No| Sat|Dinner|   2| [9.55,2.0]|  0.0|\n",
      "|      9.68|1.32|  Male|    No| Sun|Dinner|   2| [9.68,2.0]|  0.0|\n",
      "|      9.94|1.56|  Male|    No| Sun|Dinner|   2| [9.94,2.0]|  0.0|\n",
      "|     11.24|1.76|  Male|   Yes| Sat|Dinner|   2|[11.24,2.0]|  0.0|\n",
      "|     12.69| 2.0|  Male|    No| Sat|Dinner|   2|[12.69,2.0]|  0.0|\n",
      "|     15.06| 3.0|Female|    No| Sat|Dinner|   2|[15.06,2.0]|  0.0|\n",
      "|     16.99|1.01|Female|    No| Sun|Dinner|   2|[16.99,2.0]|  0.0|\n",
      "|     17.81|2.34|  Male|    No| Sat|Dinner|   4|[17.81,4.0]|  0.0|\n",
      "|     18.04| 3.0|  Male|    No| Sun|Dinner|   2|[18.04,2.0]|  0.0|\n",
      "|     18.43| 3.0|  Male|    No| Sun|Dinner|   4|[18.43,4.0]|  0.0|\n",
      "|     21.58|3.92|  Male|    No| Sun|Dinner|   2|[21.58,2.0]|  0.0|\n",
      "|     25.29|4.71|  Male|    No| Sun|Dinner|   4|[25.29,4.0]|  0.0|\n",
      "|     26.88|3.12|  Male|    No| Sun|Dinner|   4|[26.88,4.0]|  0.0|\n",
      "|     38.01| 3.0|  Male|   Yes| Sat|Dinner|   4|[38.01,4.0]|  0.0|\n",
      "|     11.02|1.98|  Male|   Yes| Sat|Dinner|   2|[11.02,2.0]|  0.0|\n",
      "|     11.69|2.31|  Male|    No|Thur| Lunch|   2|[11.69,2.0]|  1.0|\n",
      "|     12.02|1.97|  Male|    No| Sat|Dinner|   2|[12.02,2.0]|  0.0|\n",
      "|      14.0| 3.0|  Male|    No| Sat|Dinner|   2| [14.0,2.0]|  0.0|\n",
      "|     15.01|2.09|  Male|   Yes| Sat|Dinner|   2|[15.01,2.0]|  0.0|\n",
      "|     15.98|2.03|  Male|    No|Thur| Lunch|   2|[15.98,2.0]|  1.0|\n",
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_input = rf.transform(test)\n",
    "test_input.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---+\n",
      "|prediction|0.0|1.0|\n",
      "+----------+---+---+\n",
      "|       0.0| 38| 13|\n",
      "+----------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for the test data\n",
    "(lr_fit.transform(test_input)\n",
    " .select('time', 'total_bill', 'size', 'label', 'probability', 'prediction')\n",
    " .groupby('prediction') # predicted == rows;\n",
    " .pivot('label') # actual values are columns\n",
    " .count()\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Binarizer',\n",
       " 'BucketedRandomProjectionLSH',\n",
       " 'BucketedRandomProjectionLSHModel',\n",
       " 'Bucketizer',\n",
       " 'ChiSqSelector',\n",
       " 'ChiSqSelectorModel',\n",
       " 'CountVectorizer',\n",
       " 'CountVectorizerModel',\n",
       " 'DCT',\n",
       " 'DecisionTreeParams',\n",
       " 'ElementwiseProduct',\n",
       " 'FeatureHasher',\n",
       " 'HasAggregationDepth',\n",
       " 'HasCheckpointInterval',\n",
       " 'HasCollectSubModels',\n",
       " 'HasDistanceMeasure',\n",
       " 'HasElasticNetParam',\n",
       " 'HasFeaturesCol',\n",
       " 'HasFitIntercept',\n",
       " 'HasHandleInvalid',\n",
       " 'HasInputCol',\n",
       " 'HasInputCols',\n",
       " 'HasLabelCol',\n",
       " 'HasLoss',\n",
       " 'HasMaxIter',\n",
       " 'HasNumFeatures',\n",
       " 'HasOutputCol',\n",
       " 'HasOutputCols',\n",
       " 'HasParallelism',\n",
       " 'HasPredictionCol',\n",
       " 'HasProbabilityCol',\n",
       " 'HasRawPredictionCol',\n",
       " 'HasRegParam',\n",
       " 'HasSeed',\n",
       " 'HasSolver',\n",
       " 'HasStandardization',\n",
       " 'HasStepSize',\n",
       " 'HasThreshold',\n",
       " 'HasThresholds',\n",
       " 'HasTol',\n",
       " 'HasVarianceCol',\n",
       " 'HasWeightCol',\n",
       " 'HashingTF',\n",
       " 'IDF',\n",
       " 'IDFModel',\n",
       " 'Imputer',\n",
       " 'ImputerModel',\n",
       " 'IndexToString',\n",
       " 'JavaEstimator',\n",
       " 'JavaMLReadable',\n",
       " 'JavaMLWritable',\n",
       " 'JavaModel',\n",
       " 'JavaParams',\n",
       " 'JavaTransformer',\n",
       " 'LSHModel',\n",
       " 'LSHParams',\n",
       " 'MaxAbsScaler',\n",
       " 'MaxAbsScalerModel',\n",
       " 'MinHashLSH',\n",
       " 'MinHashLSHModel',\n",
       " 'MinMaxScaler',\n",
       " 'MinMaxScalerModel',\n",
       " 'NGram',\n",
       " 'Normalizer',\n",
       " 'OneHotEncoder',\n",
       " 'OneHotEncoderEstimator',\n",
       " 'OneHotEncoderModel',\n",
       " 'PCA',\n",
       " 'PCAModel',\n",
       " 'Param',\n",
       " 'Params',\n",
       " 'PolynomialExpansion',\n",
       " 'QuantileDiscretizer',\n",
       " 'RFormula',\n",
       " 'RFormulaModel',\n",
       " 'RegexTokenizer',\n",
       " 'SQLTransformer',\n",
       " 'SparkContext',\n",
       " 'StandardScaler',\n",
       " 'StandardScalerModel',\n",
       " 'StopWordsRemover',\n",
       " 'StringIndexer',\n",
       " 'StringIndexerModel',\n",
       " 'Tokenizer',\n",
       " 'TypeConverters',\n",
       " 'VectorAssembler',\n",
       " 'VectorIndexer',\n",
       " 'VectorIndexerModel',\n",
       " 'VectorSizeHint',\n",
       " 'VectorSlicer',\n",
       " 'Word2Vec',\n",
       " 'Word2VecModel',\n",
       " '_CountVectorizerParams',\n",
       " '_StringIndexerParams',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_convert_to_vector',\n",
       " '_jvm',\n",
       " 'basestring',\n",
       " 'ignore_unicode_prefix',\n",
       " 'inherit_doc',\n",
       " 'keyword_only',\n",
       " 'since',\n",
       " 'sys']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many other preprocessing steps\n",
    "dir(pyspark.ml.feature) # shows us all the stuff we can do in this library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
